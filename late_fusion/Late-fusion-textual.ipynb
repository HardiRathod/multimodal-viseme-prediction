{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c4ef44b",
   "metadata": {},
   "source": [
    "### In this notebook we have generated results from textual model for late fusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67861904",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 1500\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn import svm, datasets\n",
    "import sklearn.model_selection as model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import string\n",
    "import datetime\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import json\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d412c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a70e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict=dict()\n",
    "word_dict['<PAD>'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8e359b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Softmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d9b0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, data,label):\n",
    "        'Initialization'\n",
    "        dim_size = len(data[0][0])\n",
    "        data_lengths= [len(frame) for frame in data]\n",
    "        data_lengths_copy = [len(frame) for frame in data]\n",
    "        data_lengths_copy.sort()\n",
    "        pad_token = word_dict['<PAD>']\n",
    "        longest_frame = data_lengths_copy[-2]\n",
    "        b_s = len(data_lengths)\n",
    "        padded_X = np.ones((b_s, longest_frame,dim_size)) * pad_token\n",
    "        padded_Y = np.ones((b_s,longest_frame)) * pad_token\n",
    "\n",
    "        print(padded_X.shape)\n",
    "        for i, d_len in enumerate(data_lengths):\n",
    "            sequence = data[i]\n",
    "            sequence_y = label[i]\n",
    "            if(d_len>longest_frame):\n",
    "                continue\n",
    "            \n",
    "            padded_X[i, (longest_frame-d_len):] = sequence[:longest_frame]\n",
    "            padded_Y[i,(longest_frame-d_len):] = sequence_y[:longest_frame]\n",
    "        self.data = torch.Tensor(padded_X)\n",
    "        self.label = torch.LongTensor(padded_Y)\n",
    "        self.original_data = data\n",
    "        self.original_label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X= self.data[index]\n",
    "        y = self.label[index]\n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78b1bb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    csv_file_text = 'test_textual_feature_set_new_2.csv'\n",
    "    df = pd.read_csv(csv_file_text,header=None)\n",
    "    df = df[(df[50]== 'D') | (df[50]== 'Ah') | (df[50]== 'Ih') | (df[50]== 'Z') | (df[50]== 'W') | (df[50]== '0')  ]\n",
    "    unique_classes = df[50].unique().tolist()\n",
    "    unique_classes.remove('0')\n",
    "    indexes = [i for i in range(len(unique_classes))]\n",
    "    replace_dict = {unique_classes[i]:i for i in indexes}\n",
    "    replace_dict['0']=len(unique_classes)\n",
    "    df[[50]] = df[[50]].replace(replace_dict)\n",
    "    df_list  = df.values.tolist()\n",
    "    df_list_n_x = list()\n",
    "    df_l_sub_x=list()\n",
    "    df_list_n_y = list()\n",
    "    df_l_sub_y=list()\n",
    "    c =0\n",
    "    for i in df_list:\n",
    "        if(i[0]!=0):\n",
    "            l = i[1:len(i)-1]\n",
    "            l.insert(0,float(i[0]))\n",
    "            df_l_sub_x.append(l)\n",
    "            df_l_sub_y.append(i[len(i)-1])\n",
    "            c+=1\n",
    "        else:\n",
    "            if(len(df_l_sub_x)>0):\n",
    "                df_list_n_x.append(df_l_sub_x)\n",
    "                df_list_n_y.append(df_l_sub_y)\n",
    "            df_l_sub_x=list()\n",
    "            df_l_sub_y=list()\n",
    "    return (df_list_n_x,df_list_n_y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f19a069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader):\n",
    "    prediction_list = []\n",
    "    test_data_list = []\n",
    "    for data, target in dataloader:\n",
    "        outputs = model(data)\n",
    "        for i,dat in enumerate(outputs.data):\n",
    "            if(target[0][i]!=torch.tensor(word_dict['<PAD>']) ):\n",
    "                prediction_list.append(dat)\n",
    "                test_data_list.append(target[0][i])\n",
    "    return (test_data_list,prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88a0e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(GRUNet, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "        tag_space = self.fc(out)\n",
    "        tag_scores = m(tag_space)\n",
    "        return tag_scores.view(batch_size*len(x[0]),-1)\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d037ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_process():\n",
    "    test_set = get_data()\n",
    "    test_data = Dataset(test_set[0],test_set[1])\n",
    "    test_loader_one = torch.utils.data.DataLoader( test_data, batch_size=1, num_workers=0)\n",
    "    new_model = GRUNet(50,6,20,1)\n",
    "    new_model.load_state_dict(torch.load('grunet.pt'))\n",
    "    predictions = predict(new_model,test_loader_one)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1bd3b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(predictions):\n",
    "    csv_file_text = 'late_fusion_text_results.csv'\n",
    "    fo = open(csv_file_text,'a')\n",
    "    csv_write = csv.writer(fo)\n",
    "    for i,element in enumerate(predictions[1]):\n",
    "        t = list(element.numpy())\n",
    "        t.append(predictions[0][i].item())\n",
    "        csv_write.writerows([t])\n",
    "    fo.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "63cfb99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(predictions):\n",
    "    pred = np.array(predictions[1])\n",
    "    targ = np.array(predictions[0])\n",
    "    print(\"---------- F1 Score -----------\")\n",
    "    print(metrics.f1_score(targ, pred,average='weighted'))\n",
    "    print(\"---------- Accuracy -----------\")\n",
    "    print(metrics.accuracy_score(targ, pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68077fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162, 65, 50)\n"
     ]
    }
   ],
   "source": [
    "predictions = main_process()\n",
    "write_file(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
